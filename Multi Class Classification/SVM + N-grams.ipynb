{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers text-hammer pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e0b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup , AutoTokenizer, TFAutoModel\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import svm\n",
    "from collections import defaultdict\n",
    "import text_hammer as th\n",
    "import pandas as pd\n",
    "import tensorflow as tf , keras\n",
    "import transformers\n",
    "import random as rd\n",
    "import keras.backend as K\n",
    "from numpy.random import seed\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and specify the GPU as the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a69d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_validation_loss(model, validation_dataloader):\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in validation_dataloader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    average_val_loss = total_val_loss / len(validation_dataloader)\n",
    "    return average_val_loss\n",
    "\n",
    "def metric2(y_true, y_pred_classes):\n",
    "    n = y_true.size(0)\n",
    "    # Calculate errors where prediction is off by 1 class\n",
    "    res = torch.abs(y_true - y_pred_classes)\n",
    "    count_error = torch.sum(res == 1, dtype=torch.float32)\n",
    "    metric = 1 - count_error / n\n",
    "    return metric.item()\n",
    "\n",
    "def metric2_2(y_true, y_pred):\n",
    "    # Convert to numpy arrays for easier manipulation\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    # Calculate the number of predictions off by 1 class\n",
    "    off_by_one = np.sum(np.abs(y_true - y_pred) == 1)\n",
    "    # Calculate the metric\n",
    "    metric = 1 - off_by_one / len(y_true)\n",
    "    return metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean(x):\n",
    "    mention = r'@\\w+'\n",
    "    hash = r'#\\w+'\n",
    "    x = str(x).lower().replace('\\\\', '').replace('_', '')\n",
    "    x = re.sub(r'[^\\x00-\\x7F]+', ' ', x)\n",
    "    x = th.cont_exp(x)\n",
    "    x = th.remove_emails(x)\n",
    "    x = th.remove_urls(x)\n",
    "    x = re.sub(mention, ' ', x)\n",
    "    x = re.sub(hash, ' ', x)\n",
    "    x = th.remove_html_tags(x)\n",
    "    x = th.remove_rt(x)\n",
    "    x = th.remove_accented_chars(x)\n",
    "    x = th.remove_special_chars(x)\n",
    "    x = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", x)\n",
    "    x = re.sub(r'\\s+', ' ', x).strip()\n",
    "    x = re.sub(r'\\w*\\d+\\w*', ' ', x).strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_spss(\"/content/drive/MyDrive/VA_EN_TU_2012-2020_3000_tweets_relevant_V03_labeled_1200_cleaned.sav\")\n",
    "# Original labels: 0 - positive, 1 - negative, 2 - neutral\n",
    "# Remapping dictionary to align with RoBERTa's expected labels\n",
    "label_mapping = {1: 2, 2: 0, 3: 1}\n",
    "\n",
    "# Remapped labels: 0 - negative, 1 - neutral, 2 - positive\n",
    "df['Label_B_emotion'] = df['Label_B_emotion'].replace(label_mapping)\n",
    "df['Label_B_emotion'] = df['Label_B_emotion'].astype(int)\n",
    "dff = df[['text','Label_B_emotion']].copy()\n",
    "dff['Label_B_emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['cleaned_data'] = dff['text'].apply(get_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d59b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dff['text'].tolist()\n",
    "y = dff['Label_B_emotion'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# n-grams\n",
    "n_gram_ranges = [(1, 1), (1, 2), (1, 3)]\n",
    "val_predictions = defaultdict(list)\n",
    "#test_predictions = []\n",
    "test_predictions = {}\n",
    "val_accuracies = {}\n",
    "\n",
    "for n_gram_range in n_gram_ranges:\n",
    "    print(f\"--------------------------- {n_gram_range} ---------------------------\")\n",
    "    # TF-IDF vectorizer with different n-grams\n",
    "    vectorizer = TfidfVectorizer(ngram_range=n_gram_range, max_features=5000)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    #svm_model = SVC(kernel='linear')\n",
    "\n",
    "    val_scores = []\n",
    "    for train_index, val_index in kfold.split(X_train_tfidf):\n",
    "        X_kf_train, X_kf_val = X_train_tfidf[train_index], X_train_tfidf[val_index]\n",
    "        y_kf_train, y_kf_val = np.array(y_train)[train_index], np.array(y_train)[val_index]\n",
    "\n",
    "        svm_model = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto', random_state=42)\n",
    "        svm_model.fit(X_kf_train, y_kf_train)\n",
    "        y_val_pred = svm_model.predict(X_kf_val)\n",
    "        val_scores.append(accuracy_score(y_kf_val, y_val_pred))\n",
    "        #val_predictions[n_gram_range].append(y_val_pred)\n",
    "\n",
    "    avg_val_score = np.mean(val_scores)\n",
    "    val_accuracies[n_gram_range] = avg_val_score\n",
    "    print(f\"Average validation accuracy for n-grams {n_gram_range}: {avg_val_score}\")\n",
    "\n",
    "    svm_model.fit(X_train_tfidf, np.array(y_train))\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    y_test_pred = svm_model.predict(X_test_tfidf)\n",
    "    test_predictions[n_gram_range] = y_test_pred\n",
    "\n",
    "    test_score = accuracy_score(y_test, y_test_pred)\n",
    "    test_metric2 = metric2_2(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Test accuracy for n-grams {n_gram_range}: {test_score}\")\n",
    "    print(f\"Test metric 2 for n-grams {n_gram_range}: {test_metric2}\")\n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_test_pred,target_names=['Negative','Neutral','Positive']))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    target_names = ['negative','neutral','positive']\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=target_names,\n",
    "                yticklabels=target_names)\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix [SVM]: Raw data')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca8d49",
   "metadata": {},
   "source": [
    "#### Cleaned Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56488639",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dff['cleaned_data'].tolist()\n",
    "y = dff['Label_B_emotion'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "n_gram_ranges = [(1, 1), (1, 2), (1, 3)]\n",
    "val_predictions = defaultdict(list)\n",
    "#test_predictions = []\n",
    "test_predictions = {}\n",
    "val_accuracies = {}\n",
    "\n",
    "for n_gram_range in n_gram_ranges:\n",
    "    print(f\"--------------------------- {n_gram_range} ---------------------------\")\n",
    "    # TF-IDF vectorizer with different n-grams\n",
    "    vectorizer = TfidfVectorizer(ngram_range=n_gram_range, max_features=5000)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    #svm_model = SVC(kernel='linear')\n",
    "\n",
    "    val_scores = []\n",
    "    for train_index, val_index in kfold.split(X_train_tfidf):\n",
    "        X_kf_train, X_kf_val = X_train_tfidf[train_index], X_train_tfidf[val_index]\n",
    "        y_kf_train, y_kf_val = np.array(y_train)[train_index], np.array(y_train)[val_index]\n",
    "\n",
    "        svm_model = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto', random_state=42)\n",
    "        svm_model.fit(X_kf_train, y_kf_train)\n",
    "        y_val_pred = svm_model.predict(X_kf_val)\n",
    "        val_scores.append(accuracy_score(y_kf_val, y_val_pred))\n",
    "        #val_predictions[n_gram_range].append(y_val_pred)\n",
    "\n",
    "    avg_val_score = np.mean(val_scores)\n",
    "    val_accuracies[n_gram_range] = avg_val_score\n",
    "    print(f\"Average validation accuracy for n-grams {n_gram_range}: {avg_val_score}\")\n",
    "\n",
    "    svm_model.fit(X_train_tfidf, np.array(y_train))\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    y_test_pred = svm_model.predict(X_test_tfidf)\n",
    "    test_predictions[n_gram_range] = y_test_pred\n",
    "\n",
    "    test_score = accuracy_score(y_test, y_test_pred)\n",
    "    test_metric2 = metric2_2(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Test accuracy for n-grams {n_gram_range}: {test_score}\")\n",
    "    print(f\"Test metric 2 for n-grams {n_gram_range}: {test_metric2}\")\n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_test_pred,target_names=['Negative','Neutral','Positive']))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    target_names = ['negative','neutral','positive']\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=target_names,\n",
    "                yticklabels=target_names)\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix [SVM]: Cleaned data')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
